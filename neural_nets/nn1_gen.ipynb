{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#load data\n",
    "house_price_train = [[240,2],[260,2],[260,3],[360,2],[420,1],[350,2],[285,1]]\n",
    "size_train = [1200,1400,1900,2600,2700,2400,1150]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# creating: neural net for regression\n",
    "# No training, just generalization for example at index 1\n",
    "# 1 hidden layer, ReLu activation\n",
    "# MSE loss function, no regularization\n",
    "\n",
    "#randomly initialize weights\n",
    "weights = np.random.rand(2,3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#identify features and add bias unit\n",
    "feat = np.array(house_price_train[1])\n",
    "featBias = np.concatenate((np.ones(1), feat))\n",
    "#get z and activation (ReLu)\n",
    "z2 = np.dot(weights, featBias)\n",
    "a2 = np.maximum(0, z2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#add bias unit to second layer\n",
    "a2Bias = np.concatenate((np.ones(1), a2))\n",
    "#randomly initialize weights for second layer\n",
    "weights2 = np.random.rand(1,3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 249.4793432795336\n"
     ]
    }
   ],
   "source": [
    "#get z and activation (ReLu, hypothesis)\n",
    "z3 = np.dot(weights2, a2Bias)\n",
    "h = np.maximum(0, z3)\n",
    "print(f'Prediction: {h[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#cost function for initial (MSE)\n",
    "mse = np.square(size_train[1] - h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#computes element-wise derivative of activation function\n",
    "#vector -> vector\n",
    "def reluPrime(x):\n",
    "    new = []\n",
    "    for elem in x:\n",
    "        if elem > 0:\n",
    "            new.append(1)\n",
    "        else:\n",
    "            new.append(0)\n",
    "    return np.array(new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#backpropogate\n",
    "\n",
    "# hypothesis delta\n",
    "delta = size_train[1] - h\n",
    "# derivative of error w.r.t weights, second layer\n",
    "big_delta2 = np.multiply(a2Bias, delta)\n",
    "\n",
    "# derivative of error w.r.t weights, first layer\n",
    "# big_delta2 without bias\n",
    "delta2 = np.multiply(a2, delta)\n",
    "\n",
    "#prepare for elementwise product\n",
    "delta2_matrix = np.column_stack([delta2, delta2, delta2])\n",
    "featBias_matrix = np.row_stack([featBias, featBias])\n",
    "\n",
    "big_delta1 = np.multiply(delta2_matrix, featBias_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0.]\n"
     ]
    }
   ],
   "source": [
    "#update weights\n",
    "# learning rate\n",
    "a = 0.5\n",
    "new_weights = weights - np.multiply(a, big_delta1)\n",
    "new_weights2 = weights2 - np.multiply(a, big_delta2)\n",
    "\n",
    "z2 = np.dot(new_weights, featBias)\n",
    "a2 = np.maximum(0, z2)\n",
    "\n",
    "#add bias unit to second layer\n",
    "a2Bias = np.concatenate((np.ones(1), a2))\n",
    "#randomly initialize weights for second layer\n",
    "weights2 = np.random.rand(1,3)\n",
    "\n",
    "#get z and activation (ReLu, hypothesis)\n",
    "z3 = np.dot(new_weights2, a2Bias)\n",
    "h = np.maximum(0, z3)\n",
    "print(f'Prediction: {h}')\n",
    "# hmm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}