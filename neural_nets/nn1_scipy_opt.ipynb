{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#load data\n",
    "house_price_train = [[240,2],[260,2],[260,3],[360,2],[420,1],[350,2],[285,1]]\n",
    "size_train = [1200,1400,1900,2600,2700,2400,1150]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# creating: neural net for regression\n",
    "# Training on m=7 examples, 2 features\n",
    "# 1 hidden layer, 2 nodes, ReLu activation\n",
    "# MSE loss function, no regularization\n",
    "# scipy least_squares soon\n",
    "\n",
    "#randomly initialize weights for first and second layer\n",
    "weights = np.random.rand(2,3)\n",
    "weights2 = np.random.rand(1,3)\n",
    "\n",
    "#identify features and add bias unit\n",
    "feat = np.array(house_price_train)\n",
    "m = len(feat)\n",
    "feat_bias = np.column_stack([np.ones((m, 1)), feat])\n",
    "\n",
    "# initialize gradient accumulator\n",
    "big_delta = np.zeros([2,1,1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Forward propagates for a given training example _i_\n",
    "def propagate(i):\n",
    "    # z for second layer and activation (ReLu)\n",
    "    z2 = np.dot(weights, np.transpose(feat_bias[i, :]))\n",
    "    a2 = np.maximum(0, z2)\n",
    "    # add bias unit for second layer\n",
    "    a2_bias = np.concatenate((np.ones(1), a2))\n",
    "\n",
    "    # z for third layer and final activation (ReLu)\n",
    "    z3 = np.dot(weights2, a2_bias)\n",
    "    hypot = np.maximum(0, z3)\n",
    "\n",
    "    print(f'Prediction: {hypot}')\n",
    "\n",
    "    # Backpropagates to accumulate partials and deltas\n",
    "    # Delta for third layer (mean squared error)\n",
    "    delta3 =  (1 / m) * np.square(size_train[i] - hypot)\n",
    "    # Delta for second layer (plz work)\n",
    "    delta2 = np.dot(np.transpose(weights2),delta3) * np.append(np.array([1]), reluPrime(z2))\n",
    "\n",
    "#computes element-wise derivative of activation function\n",
    "#vector -> vector\n",
    "def reluPrime(x):\n",
    "    new = []\n",
    "    for elem in x:\n",
    "        if elem > 0:\n",
    "            new.append(1)\n",
    "        else:\n",
    "            new.append(0)\n",
    "    return np.array(new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}