{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import expit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "#load development data\n",
    "house_price_train = [[240,2],[260,2],[260,3],[360,2],[420,1],[350,2],[285,1]]\n",
    "size_train = [1200,1400,1900,2600,2700,2400,1150]\n",
    "\n",
    "house_sk_data = datasets.load_boston()\n",
    "# size of training and cross validation sets\n",
    "m_train = 400\n",
    "m_cv = 506 - m_train\n",
    "\n",
    "# training set, using features:\n",
    "# B 1000(Bk - 0.63)^2, LSTAT % lower status of the population\n",
    "# scaled for zero mean and unit variance\n",
    "house_sk_train = preprocessing.scale(house_sk_data.data[:m_train, 10:12])\n",
    "house_sk_train_bias = np.column_stack([np.ones((m_train, 1)), house_sk_train])\n",
    "\n",
    "# CV set\n",
    "house_sk_cv = preprocessing.scale(house_sk_data.data[m_train:, 10:12])\n",
    "house_sk_cv_bias = np.column_stack([np.ones((m_cv, 1)), house_sk_cv])\n",
    "\n",
    "# target set\n",
    "house_sk_target = house_sk_data.target[:m_train]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "# creating: neural net for regression\n",
    "# backpropagation from scratch\n",
    "# 2 features\n",
    "# 1 hidden layer, 2 nodes, sigmoid activation\n",
    "# MSE loss function, no regularization\n",
    "\n",
    "#randomly initialize weights for first and second layer\n",
    "weights = np.random.rand(2,3)\n",
    "weights2 = np.random.rand(1,3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "# Forward and backward propagates for a given training example _i_\n",
    "def propagate(i):\n",
    "    global weights2, weights\n",
    "\n",
    "    #learning rate\n",
    "    a = 0.05\n",
    "\n",
    "    # z for second layer and activation (ReLu)\n",
    "    z2 = np.dot(weights, np.transpose(house_sk_train_bias[i, :]))\n",
    "    a2 = expit(z2)\n",
    "    #a2 = np.maximum(0, z2)\n",
    "    # add bias unit for second layer\n",
    "    a2_bias = np.concatenate((np.ones(1), a2))\n",
    "    # z for third layer and final activation (ReLu)\n",
    "    z3 = np.dot(weights2, a2_bias)\n",
    "    hypot = z3\n",
    "    #hypot = np.maximum(0, z3)\n",
    "\n",
    "    #print(f'Prediction: {z3}')\n",
    "\n",
    "    # Backpropagates to accumulate partials and deltas\n",
    "    # Delta for third layer (mean squared error)\n",
    "    delta3 =  hypot - house_sk_target[i]\n",
    "    # derivative of error w.r.t weights, second layer\n",
    "    layer2partials = np.multiply(delta3, a2_bias)\n",
    "\n",
    "    # derivative of error w.r.t weights, first layer\n",
    "    # big_delta2 without bias\n",
    "    delta2 = np.multiply(delta3, a2)\n",
    "    delta2_matrix = np.column_stack([delta2, delta2, delta2])\n",
    "    feat_bias_matrix = np.row_stack([house_sk_train_bias[i,:], house_sk_train_bias[i,:]])\n",
    "    layer1partials = np.multiply(delta2_matrix, feat_bias_matrix)\n",
    "\n",
    "    weights2 = weights2 - a*layer2partials\n",
    "    weights = weights - a*layer1partials\n",
    "\n",
    "# todo: vectorized implementation\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "# Train weights\n",
    "for i in range(0, m_train):\n",
    "    propagate(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "# predict example in given set\n",
    "def predict(j, pred_set):\n",
    "    # z for second layer and activation (ReLu)\n",
    "    z2 = np.dot(weights, np.transpose(pred_set[j, :]))\n",
    "    #print('z2', z2)\n",
    "    a2 = expit(z2)\n",
    "    #a2 = np.maximum(0, z2)\n",
    "    #print('a2', a2)\n",
    "    # add bias unit for second layer\n",
    "    a2_bias = np.concatenate((np.ones(1), a2))\n",
    "    # z for third layer, no final activation for now\n",
    "    z3 = np.dot(weights2, a2_bias)\n",
    "\n",
    "    # calculate error\n",
    "    delta3 =  z3 - house_sk_target[j]\n",
    "    #print(f'Prediction: {z3}, actual: {house_sk_target[j]}, error: {delta3}')\n",
    "    return np.square(z3 - house_sk_target[j])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average squared CV error ($):  [34.78347861]\n"
     ]
    }
   ],
   "source": [
    "tot_err = 0\n",
    "# Predict CV example and see average error\n",
    "for j in range(0, m_cv):\n",
    "    global tot_err\n",
    "    tot_err += predict(j, house_sk_cv_bias)\n",
    "\n",
    "print('Average squared CV error ($): ', tot_err/m_cv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average squared training error ($):  [80.3780794]\n"
     ]
    }
   ],
   "source": [
    "tot_err = 0\n",
    "# Predict in training example and see average error\n",
    "for j in range(0, m_train):\n",
    "    global tot_err\n",
    "    tot_err += predict(j, house_sk_train_bias)\n",
    "\n",
    "print('Average squared training error ($): ', tot_err/m_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}